{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "`MNIST <http://yann.lecun.com/exdb/mnist/>`_ Dataset.\n",
       "\n",
       "Args:\n",
       "    root (string): Root directory of dataset where ``processed/training.pt``\n",
       "        and  ``processed/test.pt`` exist.\n",
       "    train (bool, optional): If True, creates dataset from ``training.pt``,\n",
       "        otherwise from ``test.pt``.\n",
       "    download (bool, optional): If true, downloads the dataset from the internet and\n",
       "        puts it in root directory. If dataset is already downloaded, it is not\n",
       "        downloaded again.\n",
       "    transform (callable, optional): A function/transform that  takes in an PIL image\n",
       "        and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
       "    target_transform (callable, optional): A function/transform that takes in the\n",
       "        target and transforms it.\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/conda/lib/python3.6/site-packages/torchvision/datasets/mnist.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     FashionMNIST, KMNIST, EMNIST\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets.MNIST?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = datasets.MNIST('MNIST_data/', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "data_iter = iter(trainloader)\n",
    "images, labels = data_iter.next()\n",
    "print(type(images))\n",
    "print(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4ea9ce8438>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64, 784])\n"
     ]
    }
   ],
   "source": [
    "def activation(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "inputs = images.view(images.shape[0], -1)\n",
    "print(images.shape, inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.randn(784, 256)\n",
    "b1 = torch.randn(256)\n",
    "\n",
    "w2 = torch.randn(256, 10)\n",
    "b2 = torch.randn(10)\n",
    "\n",
    "h = activation(torch.mm(inputs, w1) + b1)\n",
    "out = torch.mm(h, w2) + b2     # 属于各个数字的分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10]) torch.Size([64])\n",
      "labels:  tensor([2, 4, 8, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  0.3913, -12.5249,   7.6558,  -9.5013,   4.7528,  -3.1489, -16.7274,\n",
       "           6.7377,   2.1634,  -6.4114],\n",
       "        [ -9.7542, -15.7317,  16.6697, -12.3902,  -1.6166,  -7.1777,  -7.4016,\n",
       "          10.9677,   7.3043,  -8.9195],\n",
       "        [ -2.2503,   0.5217,   2.3960,  -8.8337,  -2.0826,  -3.5904, -19.4348,\n",
       "           4.9641,   0.7638, -12.3266],\n",
       "        [-13.3044, -19.4099,   4.5646,  -5.7069,  -0.5667,  -4.4339, -10.3709,\n",
       "           2.6410,   6.4628, -12.0158]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(out.shape, labels.shape)\n",
    "print(\"labels: \", labels[:4])\n",
    "out[:4]   # 没有经过训练，分布还对应不上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.7977e-04, 1.1792e-09, 6.8541e-01, 2.4250e-08, 3.7601e-02, 1.3917e-05,\n",
      "         1.7638e-11, 2.7368e-01, 2.8223e-03, 5.3289e-07],\n",
      "        [3.3324e-12, 8.4487e-15, 9.9659e-01, 2.3875e-13, 1.1400e-08, 4.3826e-11,\n",
      "         3.5034e-11, 3.3281e-03, 8.5345e-05, 7.6788e-12],\n",
      "        [6.6587e-04, 1.0647e-02, 6.9378e-02, 9.2096e-07, 7.8742e-04, 1.7433e-04,\n",
      "         2.2922e-11, 9.0478e-01, 1.3564e-02, 2.8010e-08],\n",
      "        [2.2185e-09, 4.9487e-12, 1.2778e-01, 4.4220e-06, 7.5507e-04, 1.5793e-05,\n",
      "         4.1694e-08, 1.8666e-02, 8.5278e-01, 8.0484e-09]])\n",
      "torch.Size([64, 10]) tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x) / torch.sum(torch.exp(x), dim=1).view(-1, 1)\n",
    "\n",
    "# 计算概率\n",
    "probs = softmax(out)\n",
    "print(probs[:4])\n",
    "print(probs.shape, probs.sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 输入768特征，输出特征256\n",
    "        self.hidden = nn.Linear(768, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forword(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        # x = F.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        # x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (5): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(768, 256),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(256, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [64 x 784], m2: [768 x 256] at /opt/conda/conda-bld/pytorch-cpu_1549626403278/work/aten/src/TH/generic/THTensorMath.cpp:940",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-5b37a47ae2c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [64 x 784], m2: [768 x 256] at /opt/conda/conda-bld/pytorch-cpu_1549626403278/work/aten/src/TH/generic/THTensorMath.cpp:940"
     ]
    }
   ],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "logits = model(images)\n",
    "loss = criterion(logits, labels)\n",
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
